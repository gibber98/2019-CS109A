{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science\n",
    "\n",
    "## Standard Section 7: Bagging and Random Forest\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2019**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Kevin Rader, and Chris Tanner<br/>\n",
    "**Section Leaders**: Marios Mattheakis, Abhimanyu (Abhi) Vasishth, Robbert (Rob) Struyven<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will work with a spam email dataset. Our ultimate goal is to be able to build models so that we can predict whether an email is spam or not spam based on word characteristics within each email. We will cover Decision Trees, Bagging, and Random Forest methods and allow you to apply it to the homework.\n",
    "\n",
    "Specifically, we will: \n",
    "    \n",
    "    1. Load in the spam dataset and split the data into train and test.\n",
    "    2. Find the optimal depth for the Decision Tree model and evaluate performance.\n",
    "    3. Fit the Bagging model using multiple bootstrapped datasets and do majority voting. \n",
    "    4. Fit the Random Forest Model and compare with Bagging.\n",
    "    \n",
    "Hopefully after this section you will be able to answer the following questions: \n",
    " - What are decision tree models?\n",
    " - How do we construct them?\n",
    " - How do we visualize them?\n",
    " - What is bagging?\n",
    " - Why does bagging help with overfitting?\n",
    " - Why does bagging help to built more expressive trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "#### The Idea: Decision Trees are just flowcharts and interpretable!\n",
    "\n",
    "<img src=\"data/flowchart.png\" alt=\"how to fix anything\" width=\"70%\"/>\n",
    "\n",
    "\n",
    "It turns out that simple flow charts can be formulated as mathematical models for classification and these models have the properties we desire;\n",
    " - interpretable by humans \n",
    " - have sufficiently complex decision boundaries \n",
    " - the decision boundaries are locally linear, each component of the decision boundary is simple to describe mathematically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----------\n",
    "\n",
    "#### Let's review some theory: \n",
    "\n",
    "#### How to build Decision Trees (the Learning Algorithm in words): \n",
    "To learn a decision tree model, we take a greedy approach: \n",
    " 1. Start with an empty decision tree (undivided feature space) \n",
    " 2. Choose the ‘optimal’ predictor on which to split and choose the ‘optimal’ threshold value for splitting by applying a **splitting criterion (1)**\n",
    " 3. Recurse on on each new node until **stopping condition (2)** is met\n",
    " \n",
    "For classification, we label each region in the model with the label of the class to which the majority of the points within the region belong. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So we need a (1) splitting criterion and a (2) stopping condition:\n",
    "\n",
    "  #### (1) Splitting criterion \n",
    "<img src=\"data/split1.png\" alt=\"split1\" width=\"70%\"/>\n",
    "\n",
    "---\n",
    "<img src=\"data/split2.png\" alt=\"split2\" width=\"70%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Stopping condition\n",
    "\n",
    "If we don’t terminate the decision tree learning algorithm manually, the tree will continue to grow until each region defined by the model possibly contains exactly one training point (and the model attains 100% training accuracy). **Not stopping while building a deeper and deeper tree = 100% training accuracy; What will your test accuracy be? What can we do to fix this?**\n",
    "\n",
    "To prevent the **overfitting** from happening, we could \n",
    "- Stop the algorithm at a particular depth. (=**not too deep**)\n",
    "- Don't split a region if all instances in the region belong to the same class. (=**stop when subtree is pure**)\n",
    "- Don't split a region if the number of instances in the sub-region will fall below pre-defined threshold (min_samples_leaf). (=**not too specific/small subtree**)\n",
    "- Don't use to many splits in the tree (=**not too many splits / not too complex global tree**)\n",
    "- Be content with <100% accuracy training set...\n",
    "\n",
    "-------------\n",
    "\n",
    "#### Done with theory, let's get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.width', 1500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-------------\n",
    "\n",
    "# Part 1 : Introduction to the Spam Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be working with a spam email dataset. The dataset has 57 predictors with a response variable called `Spam` that indicates whether an email is spam or not spam. The goal is to be able to create a classifier or method that acts as a spam filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column_1</th>\n",
       "      <th>Column_2</th>\n",
       "      <th>Column_3</th>\n",
       "      <th>Column_4</th>\n",
       "      <th>Column_5</th>\n",
       "      <th>Column_6</th>\n",
       "      <th>Column_7</th>\n",
       "      <th>Column_8</th>\n",
       "      <th>Column_9</th>\n",
       "      <th>Column_10</th>\n",
       "      <th>Column_11</th>\n",
       "      <th>Column_12</th>\n",
       "      <th>Column_13</th>\n",
       "      <th>Column_14</th>\n",
       "      <th>Column_15</th>\n",
       "      <th>Column_16</th>\n",
       "      <th>Column_17</th>\n",
       "      <th>Column_18</th>\n",
       "      <th>Column_19</th>\n",
       "      <th>Column_20</th>\n",
       "      <th>Column_21</th>\n",
       "      <th>Column_22</th>\n",
       "      <th>Column_23</th>\n",
       "      <th>Column_24</th>\n",
       "      <th>Column_25</th>\n",
       "      <th>Column_26</th>\n",
       "      <th>Column_27</th>\n",
       "      <th>Column_28</th>\n",
       "      <th>Column_29</th>\n",
       "      <th>Column_30</th>\n",
       "      <th>Column_31</th>\n",
       "      <th>Column_32</th>\n",
       "      <th>Column_33</th>\n",
       "      <th>Column_34</th>\n",
       "      <th>Column_35</th>\n",
       "      <th>Column_36</th>\n",
       "      <th>Column_37</th>\n",
       "      <th>Column_38</th>\n",
       "      <th>Column_39</th>\n",
       "      <th>Column_40</th>\n",
       "      <th>Column_41</th>\n",
       "      <th>Column_42</th>\n",
       "      <th>Column_43</th>\n",
       "      <th>Column_44</th>\n",
       "      <th>Column_45</th>\n",
       "      <th>Column_46</th>\n",
       "      <th>Column_47</th>\n",
       "      <th>Column_48</th>\n",
       "      <th>Column_49</th>\n",
       "      <th>Column_50</th>\n",
       "      <th>Column_51</th>\n",
       "      <th>Column_52</th>\n",
       "      <th>Column_53</th>\n",
       "      <th>Column_54</th>\n",
       "      <th>Column_55</th>\n",
       "      <th>Column_56</th>\n",
       "      <th>Column_57</th>\n",
       "      <th>Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column_1  Column_2  Column_3  Column_4  Column_5  Column_6  Column_7  Column_8  Column_9  Column_10  Column_11  Column_12  Column_13  Column_14  Column_15  Column_16  Column_17  Column_18  Column_19  Column_20  Column_21  Column_22  Column_23  Column_24  Column_25  Column_26  Column_27  Column_28  Column_29  Column_30  Column_31  Column_32  Column_33  Column_34  Column_35  Column_36  Column_37  Column_38  Column_39  Column_40  Column_41  Column_42  Column_43  Column_44  Column_45  Column_46  Column_47  Column_48  Column_49  Column_50  Column_51  Column_52  Column_53  Column_54  Column_55  Column_56  Column_57  Spam\n",
       "0      0.00      0.64      0.64       0.0      0.32      0.00      0.00      0.00      0.00       0.00       0.00       0.64       0.00       0.00       0.00       0.32       0.00       1.29       1.93       0.00       0.96        0.0       0.00       0.00        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.00        0.0        0.0       0.00        0.0        0.0       0.00        0.0       0.00       0.00        0.0        0.0       0.00      0.000        0.0      0.778      0.000      0.000      3.756         61        278     1\n",
       "1      0.21      0.28      0.50       0.0      0.14      0.28      0.21      0.07      0.00       0.94       0.21       0.79       0.65       0.21       0.14       0.14       0.07       0.28       3.47       0.00       1.59        0.0       0.43       0.43        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.07        0.0        0.0       0.00        0.0        0.0       0.00        0.0       0.00       0.00        0.0        0.0       0.00      0.132        0.0      0.372      0.180      0.048      5.114        101       1028     1\n",
       "2      0.06      0.00      0.71       0.0      1.23      0.19      0.19      0.12      0.64       0.25       0.38       0.45       0.12       0.00       1.75       0.06       0.06       1.03       1.36       0.32       0.51        0.0       1.16       0.06        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.00        0.0        0.0       0.06        0.0        0.0       0.12        0.0       0.06       0.06        0.0        0.0       0.01      0.143        0.0      0.276      0.184      0.010      9.821        485       2259     1\n",
       "3      0.00      0.00      0.00       0.0      0.63      0.00      0.31      0.63      0.31       0.63       0.31       0.31       0.31       0.00       0.00       0.31       0.00       0.00       3.18       0.00       0.31        0.0       0.00       0.00        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.00        0.0        0.0       0.00        0.0        0.0       0.00        0.0       0.00       0.00        0.0        0.0       0.00      0.137        0.0      0.137      0.000      0.000      3.537         40        191     1\n",
       "4      0.00      0.00      0.00       0.0      0.63      0.00      0.31      0.63      0.31       0.63       0.31       0.31       0.31       0.00       0.00       0.31       0.00       0.00       3.18       0.00       0.31        0.0       0.00       0.00        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.00        0.0        0.0       0.00        0.0        0.0       0.00        0.0       0.00       0.00        0.0        0.0       0.00      0.135        0.0      0.135      0.000      0.000      3.537         40        191     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Import Dataframe and Set Column Names\n",
    "spam_df = pd.read_csv('data/spam.csv', header=None)\n",
    "columns = [\"Column_\"+str(i+1) for i in range(spam_df.shape[1]-1)] + ['Spam']\n",
    "spam_df.columns = columns\n",
    "display(spam_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictor variabes are all continuous. They represent certain features like the frequency of the word \"`discount`\". The exact specification and description of each predictor can be found online. We are not so much interested in the exact inference of each predictor so we will omit the exact names of each of the predictors. We are more interested in the prediction of the algorithm so we will treat each as predictor without going into too much exact detail in each.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to description : https://archive.ics.uci.edu/ml/datasets/spambase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us split the dataset into a 70-30 split by using the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note :** While you will use ```train_test_split``` in your homeworks, the code below should help you visualize splitting/masking of a dataframe which will be helpful in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Set : (3262, 58)\n",
      "Shape of Testing Set : (1339, 58)\n"
     ]
    }
   ],
   "source": [
    "#Split data into train and test\n",
    "np.random.seed(42)\n",
    "msk = np.random.rand(len(spam_df)) < 0.7\n",
    "data_train = spam_df[msk]\n",
    "data_test = spam_df[~msk]\n",
    "\n",
    "#Split predictor and response columns\n",
    "x_train, y_train = data_train.drop(['Spam'], axis=1), data_train['Spam']\n",
    "x_test , y_test  = data_test.drop(['Spam'] , axis=1), data_test['Spam']\n",
    "\n",
    "print(\"Shape of Training Set :\",data_train.shape)\n",
    "print(\"Shape of Testing Set :\" ,data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column_1</th>\n",
       "      <th>Column_2</th>\n",
       "      <th>Column_3</th>\n",
       "      <th>Column_4</th>\n",
       "      <th>Column_5</th>\n",
       "      <th>Column_6</th>\n",
       "      <th>Column_7</th>\n",
       "      <th>Column_8</th>\n",
       "      <th>Column_9</th>\n",
       "      <th>Column_10</th>\n",
       "      <th>Column_11</th>\n",
       "      <th>Column_12</th>\n",
       "      <th>Column_13</th>\n",
       "      <th>Column_14</th>\n",
       "      <th>Column_15</th>\n",
       "      <th>Column_16</th>\n",
       "      <th>Column_17</th>\n",
       "      <th>Column_18</th>\n",
       "      <th>Column_19</th>\n",
       "      <th>Column_20</th>\n",
       "      <th>Column_21</th>\n",
       "      <th>Column_22</th>\n",
       "      <th>Column_23</th>\n",
       "      <th>Column_24</th>\n",
       "      <th>Column_25</th>\n",
       "      <th>Column_26</th>\n",
       "      <th>Column_27</th>\n",
       "      <th>Column_28</th>\n",
       "      <th>Column_29</th>\n",
       "      <th>Column_30</th>\n",
       "      <th>Column_31</th>\n",
       "      <th>Column_32</th>\n",
       "      <th>Column_33</th>\n",
       "      <th>Column_34</th>\n",
       "      <th>Column_35</th>\n",
       "      <th>Column_36</th>\n",
       "      <th>Column_37</th>\n",
       "      <th>Column_38</th>\n",
       "      <th>Column_39</th>\n",
       "      <th>Column_40</th>\n",
       "      <th>Column_41</th>\n",
       "      <th>Column_42</th>\n",
       "      <th>Column_43</th>\n",
       "      <th>Column_44</th>\n",
       "      <th>Column_45</th>\n",
       "      <th>Column_46</th>\n",
       "      <th>Column_47</th>\n",
       "      <th>Column_48</th>\n",
       "      <th>Column_49</th>\n",
       "      <th>Column_50</th>\n",
       "      <th>Column_51</th>\n",
       "      <th>Column_52</th>\n",
       "      <th>Column_53</th>\n",
       "      <th>Column_54</th>\n",
       "      <th>Column_55</th>\n",
       "      <th>Column_56</th>\n",
       "      <th>Column_57</th>\n",
       "      <th>Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.671</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.450</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.53</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.022</td>\n",
       "      <td>9.744</td>\n",
       "      <td>445</td>\n",
       "      <td>1257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.729</td>\n",
       "      <td>43</td>\n",
       "      <td>749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column_1  Column_2  Column_3  Column_4  Column_5  Column_6  Column_7  Column_8  Column_9  Column_10  Column_11  Column_12  Column_13  Column_14  Column_15  Column_16  Column_17  Column_18  Column_19  Column_20  Column_21  Column_22  Column_23  Column_24  Column_25  Column_26  Column_27  Column_28  Column_29  Column_30  Column_31  Column_32  Column_33  Column_34  Column_35  Column_36  Column_37  Column_38  Column_39  Column_40  Column_41  Column_42  Column_43  Column_44  Column_45  Column_46  Column_47  Column_48  Column_49  Column_50  Column_51  Column_52  Column_53  Column_54  Column_55  Column_56  Column_57  Spam\n",
       "0      0.00      0.64      0.64       0.0      0.32      0.00      0.00      0.00      0.00       0.00       0.00       0.64       0.00       0.00       0.00       0.32       0.00       1.29       1.93       0.00       0.96        0.0       0.00       0.00        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.00        0.0        0.0        0.0       0.00        0.0        0.0       0.00        0.0        0.0       0.00       0.00       0.00       0.00        0.0        0.0       0.00      0.000        0.0      0.778      0.000      0.000      3.756         61        278     1\n",
       "1      0.21      0.28      0.50       0.0      0.14      0.28      0.21      0.07      0.00       0.94       0.21       0.79       0.65       0.21       0.14       0.14       0.07       0.28       3.47       0.00       1.59        0.0       0.43       0.43        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.00        0.0        0.0        0.0       0.07        0.0        0.0       0.00        0.0        0.0       0.00       0.00       0.00       0.00        0.0        0.0       0.00      0.132        0.0      0.372      0.180      0.048      5.114        101       1028     1\n",
       "2      0.06      0.00      0.71       0.0      1.23      0.19      0.19      0.12      0.64       0.25       0.38       0.45       0.12       0.00       1.75       0.06       0.06       1.03       1.36       0.32       0.51        0.0       1.16       0.06        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.00        0.0        0.0        0.0       0.00        0.0        0.0       0.06        0.0        0.0       0.12       0.00       0.06       0.06        0.0        0.0       0.01      0.143        0.0      0.276      0.184      0.010      9.821        485       2259     1\n",
       "3      0.00      0.00      0.00       0.0      0.63      0.00      0.31      0.63      0.31       0.63       0.31       0.31       0.31       0.00       0.00       0.31       0.00       0.00       3.18       0.00       0.31        0.0       0.00       0.00        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.00        0.0        0.0        0.0       0.00        0.0        0.0       0.00        0.0        0.0       0.00       0.00       0.00       0.00        0.0        0.0       0.00      0.137        0.0      0.137      0.000      0.000      3.537         40        191     1\n",
       "4      0.00      0.00      0.00       0.0      0.63      0.00      0.31      0.63      0.31       0.63       0.31       0.31       0.31       0.00       0.00       0.31       0.00       0.00       3.18       0.00       0.31        0.0       0.00       0.00        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.00        0.0        0.0        0.0       0.00        0.0        0.0       0.00        0.0        0.0       0.00       0.00       0.00       0.00        0.0        0.0       0.00      0.135        0.0      0.135      0.000      0.000      3.537         40        191     1\n",
       "5      0.00      0.00      0.00       0.0      1.85      0.00      0.00      1.85      0.00       0.00       0.00       0.00       0.00       0.00       0.00       0.00       0.00       0.00       0.00       0.00       0.00        0.0       0.00       0.00        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.00        0.0        0.0        0.0       0.00        0.0        0.0       0.00        0.0        0.0       0.00       0.00       0.00       0.00        0.0        0.0       0.00      0.223        0.0      0.000      0.000      0.000      3.000         15         54     1\n",
       "6      0.00      0.00      0.00       0.0      1.92      0.00      0.00      0.00      0.00       0.64       0.96       1.28       0.00       0.00       0.00       0.96       0.00       0.32       3.85       0.00       0.64        0.0       0.00       0.00        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.00        0.0        0.0        0.0       0.00        0.0        0.0       0.00        0.0        0.0       0.00       0.00       0.00       0.00        0.0        0.0       0.00      0.054        0.0      0.164      0.054      0.000      1.671          4        112     1\n",
       "7      0.00      0.00      0.00       0.0      1.88      0.00      0.00      1.88      0.00       0.00       0.00       0.00       0.00       0.00       0.00       0.00       0.00       0.00       0.00       0.00       0.00        0.0       0.00       0.00        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.00        0.0        0.0        0.0       0.00        0.0        0.0       0.00        0.0        0.0       0.00       0.00       0.00       0.00        0.0        0.0       0.00      0.206        0.0      0.000      0.000      0.000      2.450         11         49     1\n",
       "8      0.15      0.00      0.46       0.0      0.61      0.00      0.30      0.00      0.92       0.76       0.76       0.92       0.00       0.00       0.00       0.00       0.00       0.15       1.23       3.53       2.00        0.0       0.00       0.15        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.15        0.0        0.0        0.0       0.00        0.0        0.0       0.00        0.0        0.0       0.30       0.00       0.00       0.00        0.0        0.0       0.00      0.271        0.0      0.181      0.203      0.022      9.744        445       1257     1\n",
       "9      0.06      0.12      0.77       0.0      0.19      0.32      0.38      0.00      0.06       0.00       0.00       0.64       0.25       0.00       0.12       0.00       0.00       0.12       1.67       0.06       0.71        0.0       0.19       0.00        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0       0.00        0.0        0.0        0.0       0.00        0.0        0.0       0.00        0.0        0.0       0.00       0.06       0.00       0.00        0.0        0.0       0.04      0.030        0.0      0.244      0.081      0.000      1.729         43        749     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df.iloc[np.arange(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that the number of spam cases is roughly evenly represented in both the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Spam in Training Set \t : 39.18%.\n",
      "Percentage of Spam in Testing Set \t : 39.96%.\n"
     ]
    }
   ],
   "source": [
    "#Check Percentage of Spam in Train and Test Set\n",
    "percentage_spam_training = 100*y_train.sum()/len(y_train)\n",
    "percentage_spam_testing  = 100*y_test.sum()/len(y_test)\n",
    "                                                  \n",
    "print(\"Percentage of Spam in Training Set \\t : {:0.2f}%.\".format(percentage_spam_training))\n",
    "print(\"Percentage of Spam in Testing Set \\t : {:0.2f}%.\".format(percentage_spam_testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "\n",
    "# Part 2 : Fitting an Optimal Single Decision Tree (by Depth) :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit here a single tree to our spam dataset and perform 5-fold cross validation on the training set. For EACH depth of the tree, we fit a tree and then compute the 5-fold CV scores. These scores are then averaged and compared across different depths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find optimal depth of trees\n",
    "mean_CV_acc = {}\n",
    "all_CV_acc = {}\n",
    "tree_depth_start, tree_depth_end, steps = 3, 31, 4\n",
    "for i in range(tree_depth_start, tree_depth_end, steps):\n",
    "    model = DecisionTreeClassifier(max_depth=i)\n",
    "    score = cross_val_score(estimator=model, X=x_train, y=y_train, cv=5, n_jobs=-1)\n",
    "    all_CV_acc[i] = score\n",
    "    mean_CV_acc[i] = score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 0.8764041147790251,\n",
       " 7: 0.8975721524522913,\n",
       " 11: 0.888674076520091,\n",
       " 15: 0.8883696739306298,\n",
       " 19: 0.8813130326307494,\n",
       " 23: 0.8846891534291315,\n",
       " 27: 0.8810124010508662}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_CV_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some dictionary manipulations for our x,y construction for the plot below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3, 7, 11, 15, 19, 23, 27],\n",
       " [0.8764041147790251,\n",
       "  0.8975721524522913,\n",
       "  0.888674076520091,\n",
       "  0.8883696739306298,\n",
       "  0.8813130326307494,\n",
       "  0.8846891534291315,\n",
       "  0.8810124010508662])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = list(mean_CV_acc.keys())\n",
    "y = list(mean_CV_acc.values())\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 7, 11, 15, 19, 23, 27),\n",
       " (0.8764041147790251,\n",
       "  0.8975721524522913,\n",
       "  0.888674076520091,\n",
       "  0.8883696739306298,\n",
       "  0.8813130326307494,\n",
       "  0.8846891534291315,\n",
       "  0.8810124010508662))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists = sorted(mean_CV_acc.items())\n",
    "x, y = zip(*lists) \n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEWCAYAAABIVsEJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd7wU5fXH8c+XLghYABtSNEaxgl57Q41GjYmamCiBWKOxG6OJJRpLQqJRFH+xROwFTYyJJYlRE/eKYgcVhKgRjQgWRCnSFIHz++PMhmXZe+/ey907d3fP+/Xa1+7OzM6c2Z2dM/M8M88jMyOEEEJorDZpBxBCCKE8RQIJIYTQJJFAQgghNEkkkBBCCE0SCSSEEEKTRAIJIYTQJJFAGklSH0nzJbVt4ufPl3Rzc8dVxHIPlTQtiX1QSy+/3EjaXdKb9YzvJ8kktWvJuBpD0u2SftVCyxoq6fESzbvF1qMxJE2WNLiBaVZpf9HaVXQCkfSYpEsLDD9Y0kdN+fOb2XtmtrqZLS1i+YMlTc/7/K/N7IeNXW4zuBI4NYn9lUITyL0j6d8tHFurY2ZPm9mm2feS3pX0tabOL9kJLpY0L3lMkvQbSd2bI15JR0sa2xzzqmcZu0l6VtJcSbMkPSNpewAzG21m+5Vy+U2RJPkFyU78U0lPSDq8OeZtZluY2ZMNTFP0/qJYOUkp+8hdx/mSdm+uZTWkohMIcDvwA0nKG/4DYLSZLWnMzFrz0WYR+gKTG5hmD6AXsFF2x9BSyvy7LdZvzawr0BM4BtgJeEZSl3TDapikbsDfgN8BawEbAJcAX6QZV5G2MbPVgU3xfcK1ki5KN6Smy0lKqyfrBck6Jo+n8z9TsjMgM6vYB7AaMBfYI2fYmsDnyRcO8A3gFeAzYBpwcc60/QADjgPeA57KGdYumeYY4HVgHvAO8KNkeBdgEbAMmJ881gcuBu7OWca38B37HOBJYEDOuHeBs4GJyXr8EehUx7q2AS4ApgIfA3cC3YGOybINWAC8Xc/3dSswGvgLcG3euLWA24APgNnAgznjDgZeTb7Dt4H9c+L/Ws50/1v3Qt9tMvxPwEfJ+j4FbJH3e45I1nEuMDYZ9nfgtLx4JwKHFFjHO4CzktcbJDGcnLz/CjALEDAYmJ4Mvyv5HRcl3+XPcuI/Kon/E+Dn9Xy3twO/yhvWFfgQPzPMDjs22Z5mA48BfXPGGXA6vp19AlyR/O4D8G16aRLfnJxlXpd8P/OAF4CNm/hfqsnOt47xRwNj82I9GXgrWfYvgY2B55Lt5D6gQzLtYGA6cH6yXu8CQ+v67oCD8O1tDvAssHU9cRnwlbxhhyXf19rJ++7ALclv8T7wK6BtzvTHs/w//m9g2/ztG9gBGJes2wzgqrztPLu/WB94ONnOpgDH5/0/7sP/u/Pw/UJNEb9NoXW8O/ntH8X/94OBTsBV+H5uBnA9OfsTfF80IflexwJbNrjspmxM5fQAbgJuznn/I+DVnPeDga3wP+LWyRd7SN6PfyeeEFYrsEF8I/ljCNgTWJizgQ0m2QnlbSTZnehXkx93X6A9vmOawvI/1rvAi8lGt1ayEZ9Yx3oem3x2I2B1PAncVd9Glvf5zsnGfyDwHfyP3CFn/N/xBLZmEuueOX+cuck6tMF3ypvl/8EKrPtK323OenTFE9/IvN/qOjzJbgC0BXZJpvse8ELOdNsAn+bGn/c9/TV5/X084f0xZ9xDhX67AuuSjf+mZLvYBj8aH1DH93s7eQkkGX5nzvIPSX7DAUA7/IDg2bzfsDbZFvoA/wF+mIw7mpwdeM4yZyW/UTv84OAPTfwfdUu+0zuAA4A188avsPwk1oeTz22RfDdP4Ntnd3xHfFTOd70E37l1xP9HC4BN8787YFv8AGnHZBs4KvltOtYRd6Gda/tkeQck7x8EbsS3w174fy57IPhdPKlsj//Hv0KS1FkxgTwH/CB5vTqwU952kt1fjCHZcQMDgZnAPjn/j8/x/2Bb4DfA80X8NnUlkNnAzvj/siNwLfAA/h/uBjwC/DKZfnt837d9suxj8f/GSv+hFZbTlI2pnB7AbvgOLruDegY4s57pRwJX5/34G+WMX2GDKPD5B4Ezcv4Y9SWQC4H7csa1STbWwTkb6LCc8b8Ffl/Hcp8gOZJO3m8KfJmz4TaUQIYlG3O7ZGObAxyajFsPPwJfs8Dnbsx+XwXG/e8PVmDdV/puC3x+jWSa7sl3s4jkzDFvuo74jnKT5P2VwPV1zHPjZN3aAL/HDyiyZxp3AD8p9NsVWJds/L1zhr0IHFHHcm+ncAK5DPhn8vofwHF528NClu+wjOTsLnl/MvBE8vpoCieQ3IOnA4E3VuG/NCCZ53R8B/wwsE6h5Sex7przfjxwTs77EcDInO96CdAlZ/x9wIX53x1wA8lOL2faN0kOaArEXHC7x89yhwLr4MlttZxxQ4Da5PVjJP/n+rZv/Gz5EqBH3jTZ7aQdsCF+ltg1Z/xvgNtz/h//yhm3ObCoiN+lrgRya9629DkrntHuDryVvL4JuChvHm/n/oaFHpVeB4KZjcV3jAdL2gjPsPdkx0vaUVKtpJmS5gInAj3yZjOtrvlLOkDS80ml4hz8T5r/+bqsjxfHZGNdlixrg5xpPsp5vRA/umlwXsnrdvgfpBhH4clsiZl9gZ/BHJWM2xCYZWazC3xuQ3xDa6r/fbeS2kq6TNLbkj7D/6Dg32cP/KhtpWUl8d4HDJPUBt8B3FVoYWb2Nl7MMxD/A/0N+EDSpviR75hGxl/s71OXDfDkB15PdY2kOcm2lC1Oy90ecrfFqfjvvsrxSfp9TiXs+YWmMbPXzexoM+sNbJkse2Q9y56R83pRgfe5scw2swU57+tat77AWdnvKPmeNqxj2oIktcfroWYl82sPfJgzvxvxMxEofvs+Di9ReEPSS5IOKjDN+vj/aF7OsKnU/3/vtAr1g7nbyrr4gdaEnPX8G8vXsy9wTt73ul5ebCuphopL8GKCI/Gj8sfNLHdDvgc/tTvAzD6XNJKVE4AVmqmkjsCfk3k/ZGZfSnoQ/9PX+bkcH+DFZ9n5Cd9g3y9qrVaeV9+c933wo7oZhSdfTlJvYG9gB0nfSQZ3xjfeHviGuJakNcxsTt7Hp+FH9YUsSOaTtW6BaXK/o+/j9Slfw5NHd/w0XHiR2ufJsiYUmM8deNIYCyw0s+fqiAk8SRyGn56/L2kM/huuiZetF9LQb9loklbH13V4MmgaMNzMRtfzsQ1ZfjFEH/x3X+X4zOxE/OCp2OnfkHQ7fgbXHNaU1CUnifQBJhWYLvsdDS8wrlgH4/+NF4EO+BlIDyt8UU192/f/mNlbwJDkAObbwP2S1s6b7AP8f9Q1J4n0oWn/92LkbhMzgMV4sWChfcI04BIzu7wxC6j4M5DEnfgf9Xh8R5OrK35U8LmkHfCdWLE64Fl9JrBE0gFA7qWMM4C167lU8z7gG5L2SY6KzsI35mcbEUPWvcCZkvonO6Zf42XrxVxp9gO8PH1T/Mh8IH40NR0YYmYf4sUr10taU1J7SXskn70FOCZZhzaSNpC0WTLuVeCIZPoafKddn674+n+KJ55fZ0ckZ2e3AldJWj85W9k5SeIkCWMZXjRS8OwjxxjgVLzYAbxe5TS8CKauyy1n4OX3q0xSR0nb4cWds/GLE8CL1M6TtEUyXXdJ3837+E+T32BD4Ay8XiobX29JHZojxgIxbybprORgg2T5Q4Dnm3Exl0jqkFyGehB+QUW+m4ATk5IDSeoi6RuSuhaxDmtJGorXpV1uZp8m2/bjwAhJ3ZJteGNJeyYfuxk4W9J2yfK+IqlvgXkPk9Qz2U6zB1krbEtmNg3/b/9GUidJW+NnLvUdMDSLZLu+GRgpqWeyLr0lZfdXo4BTJG2fjFtd0jfVwBWCVZFAzOxd/Ifrgpfb5joZuFTSPOAX+E692PnOw6+KuQ/fEXw/d/5m9ga+Y38nOS1cP+/zb+J1D7/Dj7C/CXzTzBY3Zv0St+I7zqeA/+JH66cV+dmj8DqDj3If+A4tW4z1A7xO5Q28EvPHyTq8iF+JdjVe1zSG5WdCF+JHb7Px8uH/FR3W4U78lP59vJI1f+d0NvAa8BJe/HA5K27Dd+JndHc3sJwxeLLKJpCxeMJ6qs5PeFn1BcnveHYD86/Lz5LtbFYS63hgl+xRt5k9gK/TH5IivEl4hXWuh5LPvYpf2HBLMjyDn5l8JOmTJsZXn3l4xfULkhbgv80k/KCnOXyEbycf4DvUE5P/zwrMbBx+IHhtMv0UvP6lPhMkzU+m/SFeB/qLnPFH4geD/07meT9efIOZ/Qk/Q7wH/w4exC9iyLc/MDlZzjV4XdjnBaYbgteLfIBXaF9kZv9sIP7mchb+/3oR/68+DmwCYGYvACfhdUyz8QPKYQ3NUEllSQhlT9KRwAlmtlvasZSCJMMvFJiSdizNSX43991J3UooI1VxBhIqn6TO+NnkqLRjCaFaRAIJZU/S1/F6qBk0XEwWQmgmUYQVQgihSeIMJIQQQpNUxX0gPXr0sH79+qUdRgghlJXx48d/YmY96xpfFQmkX79+jBs3Lu0wQgihrEiaWt/4KMIKIYTQJJFAQgghNEkkkBBCCE0SCSSEEEKTRAIJIYTQJJFAqsDo0dCvH7Rp48+jS972ZwihGlTFZbzVbPRoOOEEWLjQ30+d6u8Bhg5NL64QQvmLM5AK9/OfL08eWQsX+vAQQlgVkUAq3HvvNW54CCEUKxJIhevTp3HDQwihWJFAKtzw4V55nmu11Xx4CCGsikggFe5734N27WD11UHyYV//elSghxBWXSSQCjduHCxeDLffDsuWwbBh8Mgj8OabaUcWQih3kUAqXCbjz4MH+/MVV3gR1qmnQvQlFkJYFZFAKlwmA9tsA2uv7e/XXdfrP/71L/jjH9ONLYRQ3iKBVLDPP4dnnoG9915x+IknwnbbwZlnwty56cQWQih/kUAq2PPPwxdfrJxA2raFG26AGTPgoovSiS2EUP4igVSwTMYv4d1995XHbb+9n4n87nfwyistH1sIofxFAqlgmQzU1ED37oXHDx8OPXrASSf5FVohhNAYkUAq1IIF8MILKxdf5VpzTbjySp/ulltaLrYQQmWIBFKhxo6FJUtgr73qn27YMNhzTzjnHJg5s2ViCyFUhkggFSqTgfbtYddd659Oguuvh3nzPImEEEKxIoFUqNpa2Gkn6NKl4Wk33xzOOgtuu83PXEIIoRiRQCrQnDkwfnzDxVe5LrwQNtzQK9S//LJ0sYUQKkckkAr01FN+VVV9Fej5unSB//s/mDTJn0MIoSGRQCpQbS106uRFWI1x8MFw0EF+c+H06aWJLYRQOSKBVKBMBnbbDTp2bNznJD/7WLrUmzkJIYT6RAKpMDNnwsSJjav/yNW/P1xwAdx/Pzz6aPPGFkKoLJFAKsyTT/pzY+o/8p19Nmy6qTf5vmhRs4QVQqhAJU0gkvaX9KakKZLOLTC+j6RaSa9ImijpwGR4B0m3SXpN0gRJg3M+82Qyz1eTR69SrkO5qa2Frl29CZOm6tgRrrsO3n4bLr+8+WILIVSWkiUQSW2B64ADgM2BIZI2z5vsAuA+MxsEHAFcnww/HsDMtgL2BUZIyo11qJkNTB4fl2odylEm440ntmu3avPZZx8YMgQuuwzeeqt5YgshVJZSnoHsAEwxs3fMbDHwB+DgvGkM6Ja87g58kLzeHHgCIEkQc4BVOKauDh984F3VrkrxVa4RI/xsJHovDCEUUsoEsgEwLef99GRYrouBYZKmA48ApyXDJwAHS2onqT+wHbBhzuduS4qvLpSkQguXdIKkcZLGzaySRp5qa/25uRLIeuvBr34Fjz/uleohhJCrlAmk0I49/zh2CHC7mfUGDgTuSoqqbsUTzjhgJPAssCT5zNCkaGv35PGDQgs3s1FmVmNmNT179lzllSkHmYy3sLvNNs03z5NOgkGD4Mc/9vayQgghq5QJZDornjX0ZnkRVdZxwH0AZvYc0AnoYWZLzOzMpI7jYGAN4K1kuveT53nAPXhRWcATyODB3olUc2nXznsv/PBDuPji5ptvCKH8lTKBvARsIqm/pA54JfnDedO8B+wDIGkAnkBmSuosqUsyfF9giZn9OynS6pEMbw8cBEwq4TqUjf/+F959t/mKr3LtuCOccAJcc43fYxJCCFDCBGJmS4BTgceA1/GrrSZLulTSt5LJzgKOlzQBuBc42swM6AW8LOl14ByWF1N1BB6TNBF4FXgfuKlU61BOmrv+I9+vf+3FY9F7YQghS1YFl9fU1NTYuHHj0g6jpIYNg3/9y4uaCl9WsOpuvx2OOcZ7Lzz22NIsI4TQekgab2Z1XgEbd6JXADOv/9hrr9IlD4Ajj/Q2tn72M/j009ItJ4RQHiKBVID//MfPPEpVfJXVpo1XqM+ZA+eu1K5ACKHaRAKpAJmMPze1AcXG2HJLb6n35pvhuedKv7wQQusVCaQCZDLem+DGG7fM8i66CHr39gr1JUsanj6EUJkigZS5Zcu8Bd699y5t/Ueu1Vf3S3onTIBrr22ZZYYQWp9IIGVu0iT45JOWKb7KdeihcMAB3pf6+++37LJDCK1DgwlE0pWStmiJYELjtWT9Ry4Jfvc7L8I666yWXXYIoXUo5gzkDWCUpBcknSipe6mDCsWrrYWvfAX69Gn5ZW+8MZx/Pvzxj/DPf7b88kMI6WowgZjZzWa2K3Ak0A+YKOkeSS18zBvyLVni9R8tffaR66c/hU02gZNPhs8/Ty+OEELLK6oOJOkcarPk8Qne3PpPJP2hhLGFBrzyCnz2Wenv/6hPp05ekT5lClxxRXpxhBBaXjF1IFcBb+LNrf/azLYzs8vN7JvAoFIHGOqWbf8qzTMQgP32g+99D4YP925wQwjVoZgzkEnA1mb2IzN7MW9cNKWeokwGttgC1lkn7Ujg6quhQwc47bTovTCEalFMApkNtM++kbSGpEMAzGxuqQIL9Vu8GJ5+Ov2zj6z114dLL4V//AMeeCDtaEIILaGYBHJRbqIwsznARaULKRTjxRdh4cJ06z/ynXqq94Z4xhkwf37a0YQQSq2YBFJomnbNHUhonNpavxdjzz3TjmS5bO+F06fDJZekHU0IodSKSSDjJF0laWNJG0m6Ghhf6sBC/TIZGDgQ1lor7UhWtPPO8MMfep3IpOgrMoSKVkwCOQ1YDPwR+BPwOXBKKYMK9Vu0CJ59tnUVX+W67DJYYw1vbDEq1EOoXMXcSLjAzM41s5rkEt7zzGxBSwQXCnvuOa9Eb60JZO214fLLYexYuPPOtKMJIZRKMfeB9JR0haRHJGWyj5YILhSWyUDbtrD77mlHUrdjjoFddoGzz4ZZs9KOJoRQCsUUYY3G28PqD1wCvAu8VMKYQgMyGdh+e+jaNe1I6pbtvXD2bG8vK4RQeYpJIGub2S3Al2Y2xsyOBXYqcVyhDvPmwUsvtd7iq1xbbw2nnw6jRsELL6QdTQihuRWTQL5Mnj+U9A1Jg4DeJYwp1GPsWG9EsRwSCPjlvOutF70XhlCJikkgv0qacD8LOBu4GTizpFGFOmUy3mTILrukHUlxunaFkSO94ccbbkg7mhBCc6o3gSSt8G5iZnPNbJKZ7ZVcifVwC8UX8mQyfq/FaqulHUnxDjvMG1y84AL48MO0owkhNJd6E4iZLQW+1UKxhAbMnu1H8uVSfJUleZPvX3wRvReGUEmKKcJ6VtK1knaXtG32UfLIwkrGjPEb81pLA4qNsckmcO65cO+98MQTaUcTQmgOsgZuFZZUW2CwmVnZHAfX1NTYuHHj0g5jlZ1+Otx8M8yZ4/Ug5WbRIthqK28za8IE6Ngx7YhCCPWRNN7Mauoa32CjiGZWhse7lam21m8eLMfkAV5vc+21cMABMGJE3B8SQrlrMIFI+kWh4WZ2afOHE+oyY4Y3Tjh0aNqRrJr99/dK9V/+EoYMgf79044ohNBUxdSBLMh5LAUOAPqVMKZQwJNP+nO5VaAXcvXV3hRL9F4YQnkrpghrRO57SVcCcRlvC6uthW7dYNsKuHyhd2+/wfDss+Hhh+Hgg9OOKITQFMWcgeTrDGzU3IGE+mUysMceXgFdCU4/3SvUTz8dFkTbziGUpWJa431N0sTkMRl4E7im9KGFrGnT4K23KqP4Kqt9e7j+enjvPa8PCSGUn2KOZw/Keb0EmGFm0apRC6pNLqSupAQCsNtu3uz7iBFw5JGw+eZpRxRCaIxiirDWA2aZ2VQzex/oJGnHEscVctTWeidNW22VdiTN7/LLvb2sk0+OCvUQyk0xCeQGYH7O+4XJsNACzLz+Y/Bg72Oj0vTs6UlkzBi4++60owkhNEYxuyRZzu3qZraM4oq+QjN45x2vJ6i04qtcxx0HO+7oV2XNnp12NCGEYhWTQN6RdLqk9snjDOCdUgcWXKXWf+TK9l74ySfeYm8IoTwUk0BOBHYB3gemAzsCJxQzc0n7S3pT0hRJ5xYY30dSraRXkqu8DkyGd5B0W3IF2ARJg3M+s10yfIqk/5OkYmIpV5kMrLsubLpp2pGU1qBBfmPhDTd4j4shhNavwQRiZh+b2RFm1svM1jGz75vZxw19LulL5Dr8zvXNgSGS8q+zuQC4z8wGAUcA1yfDj0+WvRWwLzBCUjbWG/AEtkny2L+hWMpVtv5j7729SfRKd+mlnixPOgmWLk07mhBCQ4q5D+QOSWvkvF9T0q1FzHsHYIqZvWNmi4E/APn3HBvQLXndHfggeb058AR4AgPmADWS1gO6mdlzSb3MncAhRcRSlt54w9vAquTiq1zdusFVV8H48XDjjWlHE0JoSDFFWFub2ZzsGzObDQwq4nMbANNy3k9PhuW6GBgmaTrwCHBaMnwCcLCkdpL6A9sBGyafn97APAGQdIKkcZLGzZw5s4hwW59Mxp/Lsf+Ppjr8cNhnH2+pd8aMtKMJIdSnmATSRtKa2TeS1qK4q7AKFbrkX+k/BLjdzHoDBwJ3JUVVt+LJYRwwEngWv4mxmHn6QLNRZlZjZjU9e/YsItzWJ5OBvn2rq8Vaye9QX7TIr8oKIbRexSSQEXivhL+UdCm+M7+iiM9Nx88asnqzvIgq6zjgPgAzew7oBPQwsyVmdqaZDTSzg4E1gLeSefZuYJ4VYdkyb4G3Wuo/cn31q/Czn/l9IdlWiEMIrU8xleh3At8BZgAzgW8nwxryErCJpP6SOuCV5Pmt+L4H7AMgaQCeQGZK6iypSzJ8X2CJmf3bzD4E5knaKbn66kjgoWJWtNxMnAizZlVP/Ue+88/3M6+TT4bFi9OOJoRQSFH3Nic772vxoqVtJf29iM8sAU4FHgNex6+2mizpUknfSiY7Czhe0gTgXuDopHK8F/CypNeBc4Af5Mz6JOBmYArwNvCPYtah3FRj/UeubO+Fr7/uFeshhNanmD7RO+D1E9/HL5n9M/AXM/tr6cNrHuXYJ/pBB3kLvG++mXYk6fr2t+HRRz2R9O2bdjQhVJeG+kSv8wxE0r7J5br/BQ4D7sIbVTymnJJHOVqyBJ56qnqLr3KNHOl1QGeckXYkIYR89RVhPQZsDOxmZsOSpLGsZcKqbuPHw7x51Vt8latPH7joInjoIfhrHLaE0KrUl0C2A54H/iXpn5KOA9q2TFjVLVv/MXhwqmG0Gmee6X2FnH46LFyYdjQhhKw6E4iZvWJm55jZxvgNf4OADpL+IamotrBC09TWet8fvXqlHUnr0L69t5H17ruw3nre+GK/fjB6dNqRhVDdir0K6xkzOxW/63sksHNJo6piX3wBY8dG8VW+adOgbVv47DNvI2zqVDjhhEgiIaSpUf16JH2BPJY8Qgm88ILfhR0V6Cv6+c9XbmBx4UI46yzYYgvo3t3b0urWzc9YQgilFx1DtTK1tV5Es+eeaUfSurz3XuHhM2Z4U/C5VltteTLJTSwNvc4d1q2bn/GUyujRnhTfe88vFBg+HIYOLd3yQiiFSCCtTCbjO8Q11mh42mrSp48XW+Xr1Qt+/3uYO9eLt7LP+a+nTFn++rPPvKmYhnTp0vgklP+6a9eVuyIePdqL37IXBGSL4yCSSCgvRSWQpG+PdXKnN7M6jglDUy1cCM89Bz/+cdqRtD7Dh6+40wXo3NnvUj/00MbNywwWLKg74dSVhObOhQ8+WP563rzilte164qJ5dVX4fPPV5xm4UI/I4kEEspJgwlE0mnARXhbWNnjNgO2LmFcVemZZ+DLL6P+o5DsjrU5in0kWH11f6y/ftNjWrYM5s+vP+EUSk75ySOrrmK6EFqrYs5AzgA2NbNPSx1MtauthXbtYLfd0o6kdRo6tHUdobdps7yoqjH69StcHNenT7OEFUKLKeYy3mnA3FIHErz+Y4cd/Mg4VK7hw734LZcEF1+cSjghNFkxCeQd4ElJ50n6SfZR6sCqzWefwbhxUXxVDYYOhVGjvHFICXr29HqZZ59NO7IQGqeYBPIe8E+gA9A15xGa0dNP+30OkUCqw9Chfmf9smXw8cdw3nlw001wxx1pRxZC8RqsAzGzSwAkdfW3Nr/kUVWhTAY6doSd4x7/qnTppfD883DiiTBwIGyzTdoRhdCwBs9AJG0p6RVgEjBZ0nhJW5Q+tOqSycAuu0CnTmlHEtLQrh3cey+suSYcdphfrRVCa1dMEdYo4Cdm1tfM+uK9CN5U2rCqy6efwoQJUXxV7dZZB+67D/77Xzj6aK8XCaE1KyaBdDGz2uwbM3sS6FKyiKrQmDG+s4gGFMNuu8FvfwsPPggjRqQdTQj1K+oqLEkXSuqXPC7AeykMzSST8WYztt8+7UhCa3DmmfCd78C553rPlCG0VsUkkGOBnsBfgAeS18eUMqhqU1sLu+8OHTqkHUloDSS49VbYaCM4/HD46KO0IwqhsAYTiJnNNrPTzWxbMxtkZmeY2eyWCK4afPQR/PvfUf8RVtStG/z5z16ZfsQRsGRJ2hGFsLI6E4ikkcnzXyU9nP9ouRArW21SuxT1HyHfVlt5S8NjxsAFF6QdTQgrq+8+kLuS5ytbIpBqlcl4K635fVqEAHDkkd7I5uWX+2Xe3/pW2hGFsFx9faKPT14ONLMxuQ9gYMuEV/lqa6yd/FQAABpvSURBVGHw4NJ2XhTK2zXXwLbbejJ5++20owlhuWIq0Y8qMOzoZo6jKk2d6juEKL4K9enUCe6/31v/Peww7/I4hNagvjqQIZL+CvTPq/+oBaJp92aQrf+ICvTQkP794a67vDOq005LO5oQXH11IM8CHwI9gNxbmuYBE0sZVLWorfWWWLeIhmFCEb7xDe9Qa/hw2HVXOCYupg8pqzOBmNlUYCoQzfuVgJlXoA8evHKf2SHU5ZJLvNHFk0/2Cy8GRm1kSFExjSnuJOklSfMlLZa0VNJnLRFcJZsyBaZPj+Kr0Dht28I998Daa3t9yJw5aUcUqlkxx77XAkOAt4DVgB8CvytlUNUg6j9CU/Xq5Y0uTp0ajS6GdBVVeGJmU4C2ZrbUzG4D4rqhVZTJwPrrwyabpB1JKEe77AJXXAEPPeTPIaShwQ6lgIWSOgCvSvotXrEerfGugmz9x9e/7u0ehdAUZ5zh3eCedx7suCPsuWfaEYVqU8wZyA+AtsCpwAJgQ+A7pQyq0k2eDDNnRvFVWDUS3HwzfOUr3ujihx+mHVGoNsU0pjjVzBaZ2WdmdomZ/SQp0gpNFPUfoblkG12cNy8aXQwtr74bCV+TNLGuR0sGWWkyGb8xrG/ftCMJlWDLLeHGG73vkPPPTzuaUE3qqwM5KHk+JXnONq44FFhYsogq3NKl8OST3mFQCM1l2DBvdPGKK7yC/ZBD0o4oVIP6GlOcmtxMuKuZ/czMXkse5wJfb7kQK8uECX7tfhRfheY2ciTU1MBRR/l9RiGUWlF9okvaLftG0i4UeRWWpP0lvSlpiqRzC4zvI6lW0itJ0diByfD2ku5IitFel3RezmfeTYa/KmlcMXG0JpmMP0cDiqG5dezojS62axeNLoaWUUwCOQ64Ltlxvwtcj3dzWy9JbYHrgAOAzYEhkjbPm+wC4D4zGwQckcwb4LtARzPbCtgO+JGkfjmf28vMBppZTRHxtyqZDGy2Gay3XtqRhErUty/cfTdMnAinnNLw9CGsimKuwhpvZtsAWwPbJDvul4uY9w7AFDN7x8wWA38ADs6fPdAted0d+CBneBdJ7fC73xcDZd98ypdfwtNPR/FVKK0DDvAeDG+7DW65Je1oQiWrsxJd0jAzu1vST/KGA2BmVzUw7w2AaTnvpwM75k1zMfC4pNPwYrGvJcPvx5PNh0Bn4Ewzm5WMs+QzBtxoZqMaiKPVGDcO5s+P4qtQehdd5I0unnKKd0YVPV6GUqjvDCRbz9G1jkdDCt1jnd9qzxDgdjPrDRwI3CWpDX72shRYH+gPnCVpo+Qzu5rZtnjR2CmS9ii4cOkESeMkjZs5c2YR4ZZetv5j8OBUwwhVoG1bGD3auwuIRheLN3o09OvnLWT36+fvQ93qa879xuT5kibOezp+13pWb5YXUWUdB+yfLOc5SZ3w/ke+DzxqZl8CH0t6BqgB3jGzD5LpP5b0AJ5snioQ/yhgFEBNTU2raG6utha22QZ69Eg7klANevb0Rhf32MOvzHrggeg6oD6jR8MJJ8DC5CaFqVP9PcDQoenF1ZrVdyPh/9X3KGLeLwGbSOqftKV1BPBw3jTvAfskyxsAdAJmJsP3lusC7AS8IamLpK7J9F2A/YBJjVvldHz+uV+nH/UfoSXtvDOMGAEPPxyNLjbknHOWJ4+shQu9E69QWH03Eo5flRmb2RJJpwKP4W1p3WpmkyVdCowzs4eBs4CbJJ2JF28dbWYm6TrgNjw5CLjNzCYmxVgPJPUw7YB7zOzRVYmzpTz/vCeRqP8ILe200/zg5fzzvdHFKEJd0ZIl8LvfwfvvFx7/3nstG085kVVBZwI1NTU2bly6t4z84hfeFemsWdC9e6qhhCo0bx7ssAPMng0vv+xdCQR46SX40Y/glVegUyc/yMu32mrwzjuw7rotH1/aJI2v73aJYnok7CnpSkmPSMpkH80bZuWrrfW7hCN5hDR07eo3Gc6b5y33fvll2hGla+5cOPVUPyP76CP405+8ZePOnVecrn17WLzY2xu77750Ym3NiqlSGw28jl8NdQnwLl6/EYq0YIEXYUXxVUjTFlvATTfB2LHeh0g1MvNkMWAAXH+9X+b8+ut+pdrQoTBqlN+MKfnzbbfBa6/BRht54j38cPjkk7TXohUxs3ofwPjkeWLOsDENfa41PbbbbjtL06OPmoHZY4+lGkYIZmZ2yim+Pf75z2lH0rLeecfsgAN83QcNMnvxxeI/++WXZsOHm7Vvb9arl9mDD5YuztYEr6+uc99azBlI9mT3Q0nfkDQIvyQ3FKm21k+Fd9017UhC8KuydtgBjjkG3nor7WhK78sv4bLL/Azs6afh6qvhxRdh++2Ln0e7dn4RwrhxXn90yCF+aXS1319TTAL5laTu+BVTZwM3A2eWNKoKk8l4WWuX6Ag4tAIdO3oxTvv23q1A/qWrleSZZ/wu/PPOg/339+KqH//YE0JTbL01vPACXHih3zey5Zbw2GPNG3M5qe8+kBoAM/ubmc01s0lmtpeZbWd+CW4owty5MH583P8RWpc+fXwHOGkSnHyy1w1Uklmz4PjjYbfd/MKBhx+Gv/wFejdD2UmHDnDppV6v2a2bJ6Yf/ciXU23qOwO5SdJbki4t0IpuKNJTT8GyZZFAQuvz9a/75eV33OFXIFUCM2+NeLPNvAL87LNh8mT45jebf1k1NX5J9E9/6hcnbL21dxZXTerrUGoQ3ivhUuD+pP+NcyRFR6yNkMn49eU77ZR2JCGs7MILYb/9/GbDl4tpY7sV+89/YN994Qc/8Kumxo/3u+9XX710y+zUCX77W7+yrV07v9Ly9NMru1gwV711IGb2ppldYmabA0cBawCZpG2qUIRMxivPO3ZMO5IQVpZtdLFXL68PmT077Yga74sv4JJLYKutvJL7hhvg2We93bmWsssu3tvo6af7Xe0DB3oMla6optWSFnJ7AevgrfS2juZtW7mZM71jnyi+Cq1Zjx5eqf7++3DkkV7kWi5qa73o6OKLPQG+8QaceGI6jUZ27gzXXOMHjYsXw+67w89+Vvju9kpR79csaXdJ1+Mt6/4UGAtsamaHtERw5W7MGH+OBBJaux13hKuugr/9DS6/PO1oGjZzpie7vff2tqweewzuuad1NDey115+8+Fxx3kR2nbbeXFaJarvKqxpwGX4XeiDzGw/M7vVzOa2WHRlLpPx8tfttks7khAadsopcMQR3pthbW3a0RS2bJlX+G+6KfzhD95S7qRJXo/TmnTt6ne1/+MffiXmjjt6J1+LF6cdWfOqszFFSX3NbGoLx1MSaTWmuNlmsPHG8Pe/t/iiQ2iS+fP9JsNPP/VK9Q02SDui5SZP9uKpsWO9j5Pf/96bJGntZs/2e0/uvNPrRu64w4vdykGTG1OslOSRlg8+gDffjOKrUF5WXx3+/Gdvv621NLq4cKHfBT5woN8IeOutfrlsOSQPgDXX9KTx4IO+X6ipgV//2oveyl30T1Yi2SKAaEAxlJsBA+CWW/wu7nPPTTeWRx/1u71/8xsYNswryY85xhs7LDcHH+xnUYce6kVvu+7q61POIoGUSCbjRx4teSlhCM3l8MP93pCrrvJm4Fvahx96DAcc4Hd+19b6jYHl3h10jx7wxz96/c2UKd7MylVXwdKlaUfWNMX0B/JbSd0ktZf0hKRPJA1rieDKWW2t9/zWtm3akYTQNFde6TfAHnus36TXEpYuheuu8/rDhx7yJkMmTKi8XhQPP9zPRvbbD846y9fv7bfTjqrxijkD2c/MPsPvSp8OfBW/pDfU4b//9UcUX4Vy1qGDd6LUsaPfY7FgQWmX9+qrfkPeqad6Rf5rr/md8pV6E+6663q9yO23+7puvbX3UVJO9+EUk0DaJ88HAvea2awSxlMRsvUfUYEeyt2GG/r9FZMnw0knlabRxfnz/Si8pgbefdfvjH/8cdhkk+ZfVmsjebPwkyZ5w4+nnOJnJeXSD3sxCeSvkt4AaoAnJPUEKvjeylVXW+tNQ2weTVCGCrDvvn6n9113+b0Nzemhh/x/ctVV8MMfeqXy979fnpXkq6J3b79g4MYbvbn4Lbf0q81aeyvJDSYQMzsX2BmoMbMvgQXAwaUOrFyZeQX63ntX358gVK4LLvBmy08/3dubWlXTpnmnTIccAmus4e1G/f73fuFJtZLghBO8+aNtt/U72Q86yC/9ba2KqUT/LrDEzJZKugC4G1i/5JGVqf/8x3/wqP8IlaRNG28mfd11vf/wWU0syF6yxM82BgyAf/7TW7IdPx523rl54y1n/fv7Qeg113hpxpZbejFiazwbKaYI60IzmydpN+DrwB3ADaUNq3xlMv4c9R+h0qy9tje6+MEH3mR6Yyt7s93IZq86mjzZ+9Jo377Bj1adNm38bO/VV/2KtKFDPXF//HHaka2omASSvUL5G8ANZvYQ0KF0IZW32lqveNx447QjCaH57bADjBwJjzziN/cVY+5cv7Jqp518B3j//fDXv0K/fiUNtSJ89avej/vll3tDl1tu6S0FtBbFJJD3Jd0IfA94RFLHIj9XdZYt8wSy115R/xEq10kneUX3L34BTzxR93RmfhnwgAHeR8dpp3lTJN/5Tvw/GqNtW28W/uWXvSviww7zM5KmFiM2p2ISwfeAx4D9zWwOsBZxH0hBkybBJ59E8VWobJJfjTVgAAwZ4v2I5HvnHTjwQL9hbv31vfjqmmu8D/HQNFtsAc89551n3Xefn42k3VBrMVdhLQTeBr4u6VSgl5k9XvLIylC0fxWqRZcuXpSyaJFv7337erl9377wve/5zu6ZZzxpvPBCdGnQXNq39zO/F1/0OqmDDvKrteam1MlGMVdhnQGMxnsk7AXcLem0UgdWjjIZr/vo0yftSEIovU039YYN33rLb3wz8+c//cm7l339da8IjuZ8mt+gQX459Xnn+Z3sW20F//pXy8dRTBHWccCOZvYLM/sFsBNwfGnDKj9Ll3oPhFF8FarJww8XHv7xx62rL5FK1LGjNwv/7LPene6++8LJJ/ud/S2lmAQill+JRfI6qsDyvPKKn0ZGAgnVpK4mN8qlKY5KsOOOvv/5yU/8ZsxttvFirn79vFixXz9vHqYUikkgtwEvSLpY0sXA88AtpQmnfGXv/6i0VkNDqE9dxbVRjNuyVlsNRozwUpB58+CXv4SpU71YcepUv8O9FEmkmEr0q4BjgFnAbOAYMxvZ/KGUt0zG2/RZd920Iwmh5Qwf7sUnuTp39uGh5e2+O3TqtPLwhQu9E6vm1q6+kZLaABPNbEvg5eZffGVYvNhv9jn22LQjCaFlDR3qzz//uRdb9enjySM7PLS86dMLDy9FsWK9CcTMlkmaIKmPmUWpZh1eeskzfNR/hGo0dGgkjNakTx8vtio0vLkVUweyHjA56Y3w4eyj+UMpX5mM31y1555pRxJCqHYtWaxY7xlI4pLmX2xlyWRg4EBYa620IwkhVLuWLFasM4FI+gqwjpmNyRu+B1Cg8YLqtGiRNy9w6qlpRxJCCK6lihXrK8IaCcwrMHxhMi7gyeOLL6L5khBC9akvgfQzs4n5A81sHNCvmJlL2l/Sm5KmSDq3wPg+kmolvSJpoqQDk+HtJd0h6TVJr0s6r9h5trRMxptq2H33tCMJIYSWVV8CKXA18f+s1tCMJbUFrgMOADYHhkjK7yX8AuA+MxsEHAFcnwz/LtDRzLYCtgN+JKlfkfNsUbW13klOtDIaQqg29SWQlySt1OaVpOOA8UXMewdgipm9Y2aLgT+wcl/qBmR3vd2BD3KGd5HUDk9Wi4HPipxni5k3z1vFjOKrEEI1qu8qrB8DD0gayvKEUYP3RnhoEfPeAJiW8346sGPeNBcDjyet+3YBvpYMvx9PDB8CnYEzzWyWpGLmCYCkE4ATAPqUqF2FsWO9j+e4/yOEUI3qPAMxsxlmtgt+Ge+7yeMSM9vZzD4qYt6FGlzM7xZ+CHC7mfUGDgTuSu5+3wFvtHF9oD9wlqSNipxnNv5RZlZjZjU9e/YsItzGy2SgQwfYZZeSzD6EEFq1Bu8DMbNaoLYJ854ObJjzvjfLi6iyjgP2T5bznKROQA/g+8CjZvYl8LGkZ/Czn2lFzLPF1NbCzjuvfNNOCCFUg1L2bf4SsImk/pI64JXk+XewvwfsAyBpAF5xPzMZvrdcF7wPkjeKnGeLmD3b+yiO+o8QQrUqWQIxsyXAqXh/6q/jV1tNlnSppG8lk50FHC9pAnAvcLSZGX6l1erAJDxp3GZmE+uaZ6nWoT5jxnhTyVH/EUKoVvL9dWWrqamxcePGNes8zzgDbroJ5szxepAQQqg0ksabWU1d40tZhFXRMhnYbbdIHiGE6hUJpAk+/hgmTYriqxBCdYsE0gRPPunPkUBCCNUsEkgTZDLQtStsu23akYQQQnoigTRBJuOdR7UrpjeVEEKoUJFAGmn6dHjrrSi+CiGESCCNVJvckx83EIYQql0kkEbKZLzr2q23TjuSEEJIVySQRjDzBLLXXtAmvrkQQpWL3WAj/Pe/3kl91H+EEEIkkEbJZPw56j9CCCESSKNkMrDuurDZZmlHEkII6YsEUiQzvwJr771Bhbq1CiGEKhMJpEhvvAEffRTFVyGEkBUJpEjZ+o+oQA8hBBcJpEi1tdC3L/Tvn3YkIYTQOkQCKcKyZZ5A9tor6j9CCCErEkgRJk6EWbOi+CqEEHJFAilC3P8RQggriwRShNpa+OpXoXfvtCMJIYTWIxJIA5YsgTFj4uwjhBDyRQJpwPjxMG9e1H+EEEK+SCANyPb/MXhwqmGEEEKrEwmkAZkMbLkl9OqVdiQhhNC6RAKpxxdfwNixUXwVQgiFRAKpw+jRfuf5okVw773+PoQQwnLt0g6gNRo9Gk44ARYu9PczZ/p7gKFD04srhBBakzgDKeDnP1+ePLIWLvThIYQQXCSQAt57r3HDQwihGkUCKaBPn8YNDyGEahQJpIDhw6Fz5xWHde7sw0MIIbhIIAUMHQqjRvlVWJI/jxoVFeghhJArrsKqw9ChkTBCCKE+cQYSQgihSSKBhBBCaJJIICGEEJokEkgIIYQmiQQSQgihSWRmacdQcpJmAlPTjqMePYBP0g4iRdW8/tW87lDd618O697XzHrWNbIqEkhrJ2mcmdWkHUdaqnn9q3ndobrXvxLWPYqwQgghNEkkkBBCCE0SCaR1GJV2ACmr5vWv5nWH6l7/sl/3qAMJIYTQJHEGEkIIoUkigYQQQmiSSCApk/SupNckvSppXNrxlJqkWyV9LGlSzrC1JP1T0lvJ85ppxlgqdaz7xZLeT37/VyUdmGaMpSJpQ0m1kl6XNFnSGcnwiv/t61n3sv/tow4kZZLeBWrMrLXfUNQsJO0BzAfuNLMtk2G/BWaZ2WWSzgXWNLNz0oyzFOpY94uB+WZ2ZZqxlZqk9YD1zOxlSV2B8cAhwNFU+G9fz7p/jzL/7eMMJLQoM3sKmJU3+GDgjuT1Hfifq+LUse5Vwcw+NLOXk9fzgNeBDaiC376edS97kUDSZ8DjksZLOiHtYFKyjpl9CP5nA3qlHE9LO1XSxKSIq+KKcPJJ6gcMAl6gyn77vHWHMv/tI4Gkb1cz2xY4ADglKeYI1eMGYGNgIPAhMCLdcEpL0urAn4Efm9lnacfTkgqse9n/9pFAUmZmHyTPHwMPADukG1EqZiTlxNny4o9TjqfFmNkMM1tqZsuAm6jg319Se3wHOtrM/pIMrorfvtC6V8JvHwkkRZK6JJVqSOoC7AdMqv9TFelh4Kjk9VHAQynG0qKyO8/EoVTo7y9JwC3A62Z2Vc6oiv/t61r3Svjt4yqsFEnaCD/rAGgH3GNmw1MMqeQk3QsMxpuyngFcBDwI3Af0Ad4DvmtmFVfZXMe6D8aLMAx4F/hRtk6gkkjaDXgaeA1Ylgw+H68LqOjfvp51H0KZ//aRQEIIITRJFGGFEEJokkggIYQQmiQSSAghhCaJBBJCCKFJIoGEEEJokkggoaJJMkl35bxvJ2mmpL81cX7fShr9S4WkJyW9mTR/8YakayWtsQrzO1rS+jnv35XUo3miDZUuEkiodAuALSWtlrzfF3i/qTMzs4fN7LJmiazphprZ1sDWwBes2s13RwPrNzRRCIVEAgnV4B/AN5LXQ4B7syMk7SDpWUmvJM+bJsN/IunW5PVWkiZJ6pwcsV+bDL9d0g1JXw/vSNozaRTvdUm35yxjfs7rw7Ljiv18XcxsMfAzoI+kbZJ5DpP0YtK/xI2S2mZjkDRC0suSnpDUU9JhQA0wOpk+m2RPS6Z7TdJmTfi+Q5WIBBKqwR+AIyR1wo/aX8gZ9wawh5kNAn4B/DoZPhL4iqRDgdvwu4QXFpj3msDewJnAX4GrgS2ArSQNLCK2Vfq8mS0FJgCbSRoAHI430DkQWAoMTSbtArycNNw5BrjIzO4HxuFnNAPNbFEy7SfJdDcAZxexDqFKtUs7gBBKzcwmJs1oDwEeyRvdHbhD0iZ4kxLtk88sk3Q0MBG40cyeqWP2fzUzk/QaMMPMXgOQNBnoB7zaQHir+nkAJc/7ANsBL3nzS6zG8sYJlwF/TF7fDfyFumXHjQe+XcTyQ5WKBBKqxcPAlXjbU2vnDP8lUGtmhyZJ5smccZvgPQjWV0fwRfK8LOd19n32/5XbXlCnJny+TkkR1VZ4J0W9gDvM7LyGPpcXU75sHEuLiSFUryjCCtXiVuDS7BF+ju4sr1Q/OjtQUnfgGmAPYO2kvqCpZkgaIKkN3upqs0iaCP8NMM3MJgJPAIdJ6pWMX0tS32TyNkB2Hb4PjE1ezwO6NldMobrE0UWoCmY2HU8I+X6LF2H9BMjkDL8auN7M/iPpOKBW0lNNXPy5wN+AaXiT3as3cT5ZoyV9AXQE/oV3C4uZ/VvSBXgPl22AL4FTgKn41WhbSBoPzMXrSgBuB34vaRGw8yrGFapMtMYbQhWQNN/MVjVxhbCCKMIKIYTQJHEGEkIIoUniDCSEEEKTRAIJIYTQJJFAQgghNEkkkBBCCE0SCSSEEEKT/D++jXrTnJKWKwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot\n",
    "plt.ylabel(\"Cross Validation Accuracy\")\n",
    "plt.xlabel(\"Maximum Depth\")\n",
    "plt.title('Variation of Accuracy with Depth - Simple Decision Tree')\n",
    "plt.plot(x, y, 'b-', marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the optimal depth is found to be a depth of 7. Although, does it makes sense to choose 6?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, if we wanted to get the Confidence Bands of these results, how would we? It's as simple as a combination of getting variance using ```scores.std()``` and ```plt.fill_between()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05196923, 0.03787334, 0.0444573 , 0.04818929, 0.05285347,\n",
       "       0.05054034, 0.04774893])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stds = np.array([ np.std(score) for score in all_CV_acc.values() ])\n",
    "stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.fill_between(x, y + stds, y - stds, alpha=0.2)\n",
    "\n",
    "#Plot\n",
    "plt.ylabel(\"Cross Validation Accuracy\")\n",
    "plt.xlabel(\"Maximum Depth\")\n",
    "plt.title('Variation of Accuracy with Depth - Simple Decision Tree')\n",
    "plt.plot(x, y, 'b-', marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to display it as a boxplot we first construct a dataframe with all the scores and second we use ```sns.boxplot(...)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max Depth</th>\n",
       "      <th>CV Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.915773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0.911179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0.908116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0.903522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>0.894334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Max Depth  CV Accuracy Score\n",
       "0          3           0.915773\n",
       "1          7           0.911179\n",
       "2         11           0.908116\n",
       "3         15           0.903522\n",
       "4         19           0.894334"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a numpy array with all the CV acc scores\n",
    "scores_numpy = np.array(list(all_CV_acc.values()))\n",
    "# Making a datafr\n",
    "trees = pd.DataFrame({'Max Depth':x+x+x+x+x, 'CV Accuracy Score':list(scores_numpy[:,0])+\n",
    "                     list(scores_numpy[:,1])+\n",
    "                     list(scores_numpy[:,2])+\n",
    "                     list(scores_numpy[:,3])+\n",
    "                     list(scores_numpy[:,4])})\n",
    "trees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the boxplot \n",
    "plt.title('Variation of Accuracy with Depth - Simple Decision Tree')\n",
    "sns.boxplot(x=\"Max Depth\", y=\"CV Accuracy Score\", data=trees);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the boxplot without outliers (showfliers = False)\n",
    "plt.title('Variation of Accuracy with Depth - Simple Decision Tree')\n",
    "sns.boxplot(x=\"Max Depth\", y=\"CV Accuracy Score\", data=trees, showfliers=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's extract the best_depth value from this dictionary:** \n",
    "\n",
    "We create the new variable ```best_depth```. Can you see why we coded the best depth parameter as we did below? (Hint: Think about reproducibility.)\n",
    "\n",
    "How to sort using your own function with key parameter?\n",
    "If you want your own implementation for sorting, sorted() also accepts a key function as an optional parameter.\n",
    "\n",
    "Based on the results of the key function, you can sort the given iterable.\n",
    "\n",
    "```sorted(iterable, key=len)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27, 23, 19, 15, 11, 7, 3]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does this do? Is this the result we want?\n",
    "sorted(mean_CV_acc, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 11, 15, 23, 19, 27, 3]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does this do?\n",
    "sorted(mean_CV_acc, key=mean_CV_acc.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best depth was found to be: 7\n"
     ]
    }
   ],
   "source": [
    "#Make best depth a variable\n",
    "best_depth = sorted(mean_CV_acc, key=mean_CV_acc.get, reverse=True)[0]\n",
    "print(\"The best depth was found to be:\", best_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evalaute the performance at the best depth\n",
    "model_tree = DecisionTreeClassifier(max_depth=best_depth)\n",
    "model_tree.fit(x_train, y_train)\n",
    "\n",
    "#Check Accuracy of Spam Detection in Train and Test Set\n",
    "acc_trees_training = accuracy_score(y_train, model_tree.predict(x_train))\n",
    "acc_trees_testing  = accuracy_score(y_test,  model_tree.predict(x_test))\n",
    "\n",
    "print(\"Simple Decision Trees: Accuracy, Training Set \\t : {:.2%}\".format(acc_trees_training))\n",
    "print(\"Simple Decision Trees: Accuracy, Testing Set \\t : {:.2%}\".format(acc_trees_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Performance by Class (Lookup Confusion Matrix)\n",
    "pd.crosstab(y_test, model_tree.predict(x_test), margins=True, rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to visualize a Decision Tree with ```pydot```\n",
    "\n",
    "*Question:* Do you think this tree is interpretable? What do you think about a the maximal depth of the tree?\n",
    "\n",
    "- Let's first store the decision tree in a text format: ```decision_tree.dot```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "file_name = \"results/decision_tree.dot\"\n",
    "tree.export_graphviz(model_tree, out_file = file_name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's look at the resulting text ```decision_tree.dot```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head results/decision_tree.dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's convert our (hard to read) written decision tree (```decision_tree.dot```) into an intuitive image file format: ```image_tree.png```\n",
    "- <span style=\"color:red\">**NOTE:**</span> You might need to install the ```pydot``` package by typing the following command in your terminal: ```pip install pydot``` or you can install from within the jupyter notebook by running the following cell: ```! pip install pydot```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pydot\n",
    "! conda install graphviz -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "(graph,) = pydot.graph_from_dot_file(file_name)\n",
    "graph.write_png('results/image_tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's display the ```image_tree.png``` in markdown:\n",
    "\n",
    "Markdown: ```![title](results/image_tree.png)```. The result: \n",
    "\n",
    "![title](results/image_tree.png)\n",
    "\n",
    "*Repost Question:* Do you think this tree is interpretable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "--------\n",
    "\n",
    "\n",
    "# Part 3: Bagging and Voting\n",
    "\n",
    "*QUESTION:* Where does the word *\"Bagging\"* come from?\n",
    "\n",
    "#### Some Theory: What is bagging?\n",
    "  1. Bootstrapping: resample with replacements to get different datasets and built different models.\n",
    "  2. Do something smart to combine the different models.\n",
    "  \n",
    "One way to adjust for the high variance of the output of an experiment is to perform the experiment multiple times and then average the results. \n",
    "\n",
    " 1. **Bootstrap:** we generate multiple samples of training data, via bootstrapping. We train a full decision tree on each sample of data. \n",
    " 2. **AGgregatiING** for a given input, we output the averaged outputs of all the models for that input. \n",
    " \n",
    "This method is called **Bagging: B** ootstrap + **AGG**regat**ING**. \n",
    "\n",
    "-----------\n",
    "\n",
    "Let's bootstrap our training dataset to create multiple datasets and fit Decision Tree models to each.\n",
    "\n",
    "(Resampling: we showed live that different samples give different results for things like sums, varying more when the things we sum over have high variance themselves.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stat on all data\n",
    "data_train.mean(axis=0).to_frame('mean').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.sample(frac=1., replace=True).mean(axis=0).to_frame('mean').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we actually fit the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = 100 # we tried a variety of numbers here\n",
    "choosen_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating model\n",
    "np.random.seed(0)\n",
    "model = DecisionTreeClassifier(max_depth=choosen_depth)\n",
    "\n",
    "#Initializing variables\n",
    "predictions_train = np.zeros((data_train.shape[0], n_trees))\n",
    "predictions_test = np.zeros((data_test.shape[0], n_trees))\n",
    "\n",
    "#Conduct bootstraping iterations\n",
    "for i in range(n_trees):\n",
    "    temp = data_train.sample(frac=1, replace=True)\n",
    "    response_variable = temp['Spam']\n",
    "    temp = temp.drop(['Spam'], axis=1)\n",
    "    \n",
    "    model.fit(temp, response_variable)  \n",
    "    predictions_train[:,i] = model.predict(x_train)   \n",
    "    predictions_test[:,i] = model.predict(x_test)\n",
    "    \n",
    "#Make Predictions Dataframe\n",
    "columns = [\"Bootstrap-Model_\"+str(i+1) for i in range(n_trees)]\n",
    "predictions_train = pd.DataFrame(predictions_train, columns=columns)\n",
    "predictions_test = pd.DataFrame(predictions_test, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_train['Spam'].values\n",
    "y_test = data_test['Spam'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example Bolean for locating the Non Spam\n",
    "y == 0\n",
    "## Example Bolean for locating the Spam\n",
    "y == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_avg = 100\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 7))\n",
    "for (ax, label, predictions, y) in [\n",
    "    (axs[0], 'Training Set', predictions_train, y_train), \n",
    "    (axs[1], 'Test Set' , predictions_test , y_test ) ]:\n",
    "    \n",
    "    # Take the average\n",
    "    mean_predictions = predictions.iloc[:,:num_to_avg].mean(axis=1)\n",
    "    \n",
    "    # Plot the Spam\n",
    "    mean_predictions[y == 1].hist(density=True, histtype='step', \n",
    "                                  range=[0,1], label='Spam', lw=2, ax=ax)\n",
    "    \n",
    "    # Plot the non Spam\n",
    "    mean_predictions[y == 0].hist(density=True, histtype='step', \n",
    "                                  range=[0,1], label='Not-Spam', lw=2, ax=ax)\n",
    "    ax.legend(loc='upper center');\n",
    "    ax.set_xlabel(\"Mean of ensemble predictions (0.5=50 True - 50 False)\")\n",
    "    ax.set_title(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now get final predictions: majority voting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to ensemble the prediction of each bagged decision tree model\n",
    "def get_prediction(df, count=-1):\n",
    "    count = df.shape[1] if count==-1 else count\n",
    "    temp = df.iloc[:,0:count]\n",
    "    return np.mean(temp, axis=1)>0.5\n",
    "\n",
    "#Check Accuracy of Spam Detection in Train and Test Set\n",
    "acc_bagging_training = 100*accuracy_score(y_train, get_prediction(predictions_train, count=-1))\n",
    "acc_bagging_testing  = 100*accuracy_score(y_test, get_prediction(predictions_test, count=-1))\n",
    "\n",
    "print(\"Bagging: \\tAccuracy, Training Set \\t: {:0.2f}%\".format(acc_bagging_training))\n",
    "print(\"Bagging: \\tAccuracy, Testing Set \\t: {:0.2f}%\".format( acc_bagging_testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count in the above code can be use to define the number of models the voting in the dataframe should be based on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Performance by Class (Lookup Confusion Matrix)\n",
    "pd.crosstab(np.array(y_test), model.predict(x_test), margins=True, rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Food for Thought :** Are these bagging models independent of each other, can they be trained in a parallel fashion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 : Random Forest vs Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Random Forest? \n",
    "\n",
    "- **Many trees** make a **forest**.\n",
    "- **Many random trees** make a **random forest**.\n",
    "\n",
    "\n",
    "Random Forest is a modified form of bagging that creates ensembles of independent decision trees. \n",
    "To *de-correlate the trees*, we: \n",
    "1. train each tree on a separate bootstrap **random sample** of the full training set (same as in bagging) \n",
    "2. for each tree, at each split, we **randomly select a set of 𝐽′ predictors from the full set of predictors.** (not done in bagging)\n",
    "3. From amongst the 𝐽′  predictors, we select the optimal predictor and the optimal corresponding threshold for the split. \n",
    "\n",
    "*Question:* Why would this second step help (only considering random sub-group of features)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will fit an ensemble method, the Random Forest technique, which is different from the decision tree. Refer to the lectures slides for a full treatment on how they are different. Let's use ```n_estimators = predictor_count/2``` and ```max_depth = best_depth```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit a Random Forest Model\n",
    "\n",
    "#Training\n",
    "model = RandomForestClassifier(n_estimators=int(x_train.shape[1]/2), max_depth=best_depth)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred_train = model.predict(x_train)\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "#Perfromance Evaluation\n",
    "acc_random_forest_training = accuracy_score(y_train, y_pred_train)*100\n",
    "acc_random_forest_testing = accuracy_score(y_test, y_pred_test)*100\n",
    "\n",
    "print(\"Random Forest: Accuracy, Training Set : {:0.2f}%\".format(acc_random_forest_training))\n",
    "print(\"Random Forest: Accuracy, Testing Set :  {:0.2f}%\".format(acc_random_forest_testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's compare the performance of our 3 models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Decision Trees:\\tAccuracy, Training Set \\t: {:.2%}\".format(acc_trees_training))\n",
    "print(\"Decision Trees:\\tAccuracy, Testing Set \\t: {:.2%}\".format(acc_trees_testing))\n",
    "\n",
    "print(\"\\nBagging: \\tAccuracy, Training Set \\t: {:0.2f}%\".format(acc_bagging_training))\n",
    "print(\"Bagging: \\tAccuracy, Testing Set \\t: {:0.2f}%\".format( acc_bagging_testing))\n",
    "\n",
    "print(\"\\nRandom Forest: \\tAccuracy, Training Set \\t: {:0.2f}%\".format(acc_random_forest_training))\n",
    "print(\"Random Forest: \\tAccuracy, Testing Set \\t: {:0.2f}%\".format(acc_random_forest_testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we see above, the performance of both Bagging and Random Forest was similar, so what is the difference? Do both overfit the data just as much?\n",
    "\n",
    "Hints :\n",
    "\n",
    "- What is the only extra parameter we declared when defining a Random Forest Model vs Bagging? Does it have an impact on overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit a Random Forest Model\n",
    "\n",
    "new_depth = best_depth + 20 \n",
    "\n",
    "#Training\n",
    "model = RandomForestClassifier(n_estimators=int(x_train.shape[1]/2), max_depth=new_depth)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred_train = model.predict(x_train)\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "#Perfromance Evaluation\n",
    "acc_random_forest_deeper_training = accuracy_score(y_train, y_pred_train)*100\n",
    "acc_random_forest_deeper_testing = accuracy_score(y_test, y_pred_test)*100\n",
    "\n",
    "print(\"Random Forest: Accuracy, Training Set (Deeper): {:0.2f}%\".format(acc_random_forest_deeper_training))\n",
    "print(\"Random Forest: Accuracy, Testing Set (Deeper):  {:0.2f}%\".format(acc_random_forest_deeper_testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Accuracies:\")\n",
    "print(\"Decision Trees:\\tAccuracy, Training Set \\t: {:.2%}\".format(acc_trees_training))\n",
    "print(\"Bagging: \\tAccuracy, Training Set \\t: {:0.2f}%\".format(acc_bagging_training))\n",
    "print(\"Random Forest: \\tAccuracy, Training Set \\t: {:0.2f}%\".format(acc_random_forest_training))\n",
    "print(\"RF Deeper: \\tAccuracy, Training Set \\t: {:0.2f}%\".format(acc_random_forest_deeper_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing Accuracies:\")\n",
    "print(\"Decision Trees:\\tAccuracy, Testing Set \\t: {:.2%}\".format(acc_trees_testing))\n",
    "print(\"Bagging: \\tAccuracy, Testing Set \\t: {:0.2f}%\".format( acc_bagging_testing))\n",
    "print(\"Random Forest: \\tAccuracy, Testing Set \\t: {:0.2f}%\".format(acc_random_forest_testing))\n",
    "print(\"RF Deeper:  \\tAccuracy, Testing Set \\t: {:0.2f}%\".format(acc_random_forest_deeper_testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance\n",
    "Random Forest gives the above values as ```feature_importance``` where it normalizes the impact of a predictor to the number of times it is useful and thus gives overvall significance for free. Explore the attributes of the Random Forest model object for the best nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top Features\n",
    "feature_importance = model.feature_importances_\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "#Plot\n",
    "plt.figure(figsize=(10,12))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, x_train.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our Initial Questions:\n",
    "\n",
    "- What are decision tree models?\n",
    "- How do we construct them?\n",
    "- How do we vizualize them?\n",
    "- What is the idea of bagging?\n",
    "- Why does bagging help with overfitting?\n",
    "- Why does bagging help to built more expressive trees?\n",
    "\n",
    "#### End of Standard Section. What about next week? \n",
    "\n",
    "**Gradient Boosting etc.. building upon decision trees. Why should we care?** \n",
    "\n",
    "<img src=\"data/kaggle.png\" alt=\"tree_adj\" width=\"100%\"/>\n",
    "\n",
    "\n",
    "----------\n",
    "<img src=\"data/trees_adj.png\" alt=\"tree_adj\" width=\"100%\"/>\n",
    "\n",
    "[Source Medion: \"XGBoost Algorithm: Long May She Reign!\"](https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
